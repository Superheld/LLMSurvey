{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77d41461",
   "metadata": {},
   "source": [
    "# One Shot\n",
    "\n",
    "Ziel ist es, mit einem Request alle Antworten zu erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff08db68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import time\n",
    "import survey.models \n",
    "from tqdm.notebook import tqdm\n",
    "from survey.request import Request\n",
    "\n",
    "\n",
    "# strategie laden\n",
    "strategies = survey.models.StrategyModel()\n",
    "strategies.load_strategies('oneshot_%')\n",
    "strategies_list = strategies.get_strategies()\n",
    "\n",
    "# fragen laden\n",
    "questions = survey.models.QuestionsModel()\n",
    "questions_list = questions.get_questions()\n",
    "\n",
    "# models laden\n",
    "models = survey.models.ModelsModel()\n",
    "models_list = models.get_models()\n",
    "\n",
    "# request und response laden\n",
    "run = survey.models.RunModel()\n",
    "requests = Request()\n",
    "response = survey.models.ResponseModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea3b8c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Strategies: 4 - [<sqlite3.Row object at 0x7f62150dc2e0>, <sqlite3.Row object at 0x7f6213069960>, <sqlite3.Row object at 0x7f621306b850>, <sqlite3.Row object at 0x7f623c29c0d0>]\n",
      "Questions: 29\n",
      "Models: 10\n"
     ]
    }
   ],
   "source": [
    "print(f\"Strategies: {len(strategies_list)} - {strategies_list}\")\n",
    "print(f\"Questions: {len(questions_list)}\")\n",
    "print(f\"Models: {len(models_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb594cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f4b7440a3947f29b85e94977a4dc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Strategies:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Strategy: oneshot_none\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182f16d6182e4007887248e75cafa819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Models (oneshot_none):   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    anthropic/claude-haiku-4-5-20251001 \n",
      "=== Model: anthropic/claude-haiku-4-5-20251001 ===\n",
      "    anthropic/claude-opus-4-5-20251101 \n",
      "=== Model: anthropic/claude-opus-4-5-20251101 ===\n",
      "    deepseek/deepseek-chat \n",
      "=== Model: deepseek/deepseek-chat ===\n",
      "    deepseek/deepseek-reasoner \n",
      "=== Model: deepseek/deepseek-reasoner ===\n",
      "    gemini/gemini-3-flash-preview \n",
      "=== Model: gemini/gemini-3-flash-preview ===\n",
      "    gemini/gemini-3-pro-preview \n",
      "=== Model: gemini/gemini-3-pro-preview ===\n",
      "    mistral/mistral-large-2512 \n",
      "=== Model: mistral/mistral-large-2512 ===\n",
      "    mistral/mistral-small-2506 \n",
      "=== Model: mistral/mistral-small-2506 ===\n",
      "    openai/gpt-5-nano-2025-08-07 \n",
      "=== Model: openai/gpt-5-nano-2025-08-07 ===\n",
      "    openai/gpt-5.2-2025-12-11 \n",
      "=== Model: openai/gpt-5.2-2025-12-11 ===\n",
      "\n",
      "  Strategy: oneshot_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c333934f084e9a87cb3f8af2e0c7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Models (oneshot_test):   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    anthropic/claude-haiku-4-5-20251001 \n",
      "=== Model: anthropic/claude-haiku-4-5-20251001 ===\n",
      "    anthropic/claude-opus-4-5-20251101 \n",
      "=== Model: anthropic/claude-opus-4-5-20251101 ===\n",
      "    deepseek/deepseek-chat \n",
      "=== Model: deepseek/deepseek-chat ===\n",
      "    deepseek/deepseek-reasoner \n",
      "=== Model: deepseek/deepseek-reasoner ===\n",
      "    gemini/gemini-3-flash-preview \n",
      "=== Model: gemini/gemini-3-flash-preview ===\n",
      "    gemini/gemini-3-pro-preview \n",
      "=== Model: gemini/gemini-3-pro-preview ===\n",
      "    mistral/mistral-large-2512 \n",
      "=== Model: mistral/mistral-large-2512 ===\n",
      "    mistral/mistral-small-2506 \n",
      "=== Model: mistral/mistral-small-2506 ===\n",
      "    openai/gpt-5-nano-2025-08-07 \n",
      "=== Model: openai/gpt-5-nano-2025-08-07 ===\n",
      "    openai/gpt-5.2-2025-12-11 \n",
      "=== Model: openai/gpt-5.2-2025-12-11 ===\n",
      "\n",
      "  Strategy: oneshot_llm_opinion\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "621b28bf484f46e5867cba24a39b144e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Models (oneshot_llm_opinion):   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    anthropic/claude-haiku-4-5-20251001 \n",
      "=== Model: anthropic/claude-haiku-4-5-20251001 ===\n",
      "    anthropic/claude-opus-4-5-20251101 \n",
      "=== Model: anthropic/claude-opus-4-5-20251101 ===\n",
      "    deepseek/deepseek-chat \n",
      "=== Model: deepseek/deepseek-chat ===\n",
      "    deepseek/deepseek-reasoner \n",
      "=== Model: deepseek/deepseek-reasoner ===\n",
      "    gemini/gemini-3-flash-preview \n",
      "=== Model: gemini/gemini-3-flash-preview ===\n",
      "    gemini/gemini-3-pro-preview \n",
      "=== Model: gemini/gemini-3-pro-preview ===\n",
      "    mistral/mistral-large-2512 \n",
      "=== Model: mistral/mistral-large-2512 ===\n",
      "    mistral/mistral-small-2506 \n",
      "=== Model: mistral/mistral-small-2506 ===\n",
      "    openai/gpt-5-nano-2025-08-07 \n",
      "=== Model: openai/gpt-5-nano-2025-08-07 ===\n",
      "    openai/gpt-5.2-2025-12-11 \n",
      "=== Model: openai/gpt-5.2-2025-12-11 ===\n",
      "\n",
      "  Strategy: oneshot_llm_explicit\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9632efbd314ea59033f6c66e570bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Models (oneshot_llm_explicit):   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    anthropic/claude-haiku-4-5-20251001 \n",
      "=== Model: anthropic/claude-haiku-4-5-20251001 ===\n",
      "    anthropic/claude-opus-4-5-20251101 \n",
      "=== Model: anthropic/claude-opus-4-5-20251101 ===\n",
      "    deepseek/deepseek-chat \n",
      "=== Model: deepseek/deepseek-chat ===\n",
      "    deepseek/deepseek-reasoner \n",
      "=== Model: deepseek/deepseek-reasoner ===\n",
      "    gemini/gemini-3-flash-preview \n",
      "=== Model: gemini/gemini-3-flash-preview ===\n",
      "    gemini/gemini-3-pro-preview \n",
      "=== Model: gemini/gemini-3-pro-preview ===\n",
      "    mistral/mistral-large-2512 \n",
      "=== Model: mistral/mistral-large-2512 ===\n",
      "    mistral/mistral-small-2506 \n",
      "=== Model: mistral/mistral-small-2506 ===\n",
      "    openai/gpt-5-nano-2025-08-07 \n",
      "=== Model: openai/gpt-5-nano-2025-08-07 ===\n",
      "    openai/gpt-5.2-2025-12-11 \n",
      "=== Model: openai/gpt-5.2-2025-12-11 ===\n"
     ]
    }
   ],
   "source": [
    "for strategy in tqdm(strategies_list, desc=\"Strategies\"):\n",
    "\n",
    "    print(f\"\\n  Strategy: {strategy['name']}\")\n",
    "\n",
    "    # prompts lesen\n",
    "    with open(f\"../{strategy['system_path']}\", \"r\") as f:\n",
    "        system_prompt = f.read()\n",
    "\n",
    "    with open(f\"../{strategy['message_path']}\", \"r\") as f:\n",
    "        message_prompt = f.read()\n",
    "\n",
    "    # questions\n",
    "    questions_text = \"\\n\".join([f\"{id}. {text}\" for id, text in questions_list])\n",
    "    message = message_prompt.replace(\"{questions}\", questions_text)\n",
    "\n",
    "\n",
    "    for model_db_id, model_id in tqdm(models_list, desc=f\"  Models ({strategy['name']})\"):\n",
    "\n",
    "        print(f\"    {model_id}\", end=\" \", flush=True)\n",
    "\n",
    "        # Run sichern\n",
    "        run_id = run.write_run(model_db_id, strategy['id'])\n",
    "\n",
    "        # Befragung\n",
    "        start_time = time.time()\n",
    "\n",
    "        answer = requests.request_model(model_id, system_prompt, message, 'COMPLETE')\n",
    "\n",
    "        duration_time = time.time() - start_time\n",
    "\n",
    "        # DEBUG - Was kommt zurÃ¼ck?\n",
    "        print(f\"\\n=== Model: {model_id} ===\")\n",
    "\n",
    "        try:\n",
    "            response.write_respone(run_id, None, answer, 'COMPLETE')\n",
    "            run.update_run(answer.usage.prompt_tokens, answer.usage.completion_tokens, duration_time, run_id)\n",
    "        except Exception as e:\n",
    "                print(f\"    --- Error {e} ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
